{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective : \n",
    "\n",
    "The objective of this case study is demonstrate a technique called **Voting based Classification**, which basically involves aggregating the results of a relatively handful of predictors each built upon a separate classification algorithm and trained on exactly the same training dataset,to predict the class of an instance. The results could be aggregated in the framework of either *Soft Voting* scheme : one in which, for a particular instance of the test set, the probabilities of prediction of a particular class label are averaged across all the classifiers and the class label that corresponds to the highest value is assigned to the instance or *Hard Voting* scheme : one in which, for an instance of the test set, the class label that has been predicted by the maximum number of predictors is assigned. All the predictors are trained in parallel.\n",
    "\n",
    "\n",
    "The dataset that will be used for demonstration is popular by the name of **US adult income** dataset. The classification goal, in the context of the dataset, would be to predict whether or not the annual income corresponding to an instance, for a given combination of values of its attributes is greater than 50,000 dollars.\n",
    "\n",
    "### Data :\n",
    "\n",
    "#### Data Source : https://www.kaggle.com/wenruliu/adult-income-dataset\n",
    "\n",
    "#### Attributes of the dataset :\n",
    "\n",
    "***Input Features*** :\n",
    "\n",
    "1) age : Continuous\n",
    "\n",
    "2) workclass : Categorical\n",
    "\n",
    "3) fnlwgt : Continuous : Number of instances in the original dataset that have exactly the same set of values\n",
    "\n",
    "4) education : Categorical\n",
    "\n",
    "5) Education-num : Continuous\n",
    "\n",
    "6) marital-status : Categorical\n",
    "\n",
    "7) occupation : Categorical\n",
    "\n",
    "8) relationship : Categorical\n",
    "\n",
    "9) race : Categorical\n",
    "\n",
    "10) sex : Categorical\n",
    "\n",
    "11) capital-gain : Categorical\n",
    "\n",
    "12) capital-loss : Categorical\n",
    "\n",
    "13) Hours-per-week : Categorical\n",
    "\n",
    "14) country : Categorical\n",
    "\n",
    "***Target Feature***:\n",
    "\n",
    "Income : Categorical: lesser than or greater than 50k?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Importing the relevant libraries :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Loading the dataset :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>226802</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>89814</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>336951</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>160323</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>103497</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  workclass  fnlwgt     education  educational-num      marital-status  \\\n",
       "0   25    Private  226802          11th                7       Never-married   \n",
       "1   38    Private   89814       HS-grad                9  Married-civ-spouse   \n",
       "2   28  Local-gov  336951    Assoc-acdm               12  Married-civ-spouse   \n",
       "3   44    Private  160323  Some-college               10  Married-civ-spouse   \n",
       "4   18        NaN  103497  Some-college               10       Never-married   \n",
       "\n",
       "          occupation relationship   race  gender  capital-gain  capital-loss  \\\n",
       "0  Machine-op-inspct    Own-child  Black    Male             0             0   \n",
       "1    Farming-fishing      Husband  White    Male             0             0   \n",
       "2    Protective-serv      Husband  White    Male             0             0   \n",
       "3  Machine-op-inspct      Husband  Black    Male          7688             0   \n",
       "4                NaN    Own-child  White  Female             0             0   \n",
       "\n",
       "   hours-per-week native-country income  \n",
       "0              40  United-States  <=50K  \n",
       "1              50  United-States  <=50K  \n",
       "2              40  United-States   >50K  \n",
       "3              40  United-States   >50K  \n",
       "4              30  United-States  <=50K  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "income_data=pd.read_csv('adult.csv',sep=',',skipinitialspace=True,na_values='?')\n",
    "income_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Checking for class imbalance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<=50K    37155\n",
       ">50K     11687\n",
       "Name: income, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "income_data['income'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) Checking for missing values :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48842 entries, 0 to 48841\n",
      "Data columns (total 15 columns):\n",
      "age                48842 non-null int64\n",
      "workclass          46043 non-null object\n",
      "fnlwgt             48842 non-null int64\n",
      "education          48842 non-null object\n",
      "educational-num    48842 non-null int64\n",
      "marital-status     48842 non-null object\n",
      "occupation         46033 non-null object\n",
      "relationship       48842 non-null object\n",
      "race               48842 non-null object\n",
      "gender             48842 non-null object\n",
      "capital-gain       48842 non-null int64\n",
      "capital-loss       48842 non-null int64\n",
      "hours-per-week     48842 non-null int64\n",
      "native-country     47985 non-null object\n",
      "income             48842 non-null object\n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 5.6+ MB\n"
     ]
    }
   ],
   "source": [
    "income_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5) Label Encoding all the features:\n",
    "\n",
    "Label Encoding is the process of assigning numerical labels to values contained within categorical input features of the\n",
    "dataframe. Label Encoding is performed inorder to facilitate the application of predictive mathematical models such\n",
    "as **Logistic Regression**, **Support Vector Machines**, **Naive-Baye's** etc, to those datasets which contain categorical/non-numerical data. Label Encoding is performed in two stages which are as follows:\n",
    "\n",
    "1) The Categorical attributes have to be fetched from the main dataframe.\n",
    "\n",
    "2) The values contained within the categorical attributes have been assigned numerical labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4, 5, 6, 7, 8, 12, 13]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting rid of duplicated columns:\n",
    "income_data=income_data.drop(labels='education',axis=1)\n",
    "\n",
    "#getting rid of rows containing missing values:\n",
    "income_data.dropna(inplace=True)\n",
    "\n",
    "#fetching categorical indices\n",
    "categorical_features=income_data.loc[:,'age':'income'].select_dtypes(include=object).columns\n",
    "categorical_indices=[]\n",
    "for feature in categorical_features:\n",
    "    categorical_indices.append(income_data.columns.get_loc(feature))\n",
    "\n",
    "#label encoding the categorical features:\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder_object=LabelEncoder()\n",
    "for count in categorical_indices:\n",
    "    income_data.iloc[:,count]=encoder_object.fit_transform(income_data.iloc[:,count])\n",
    "\n",
    "#displaying the categorical indices:\n",
    "categorical_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6) OneHotEncoding the LabelEncoded input features :\n",
    "\n",
    "In order to facilitate the application of mathamatical models to datasets, merely assigning numerical labels to categorical attributes is simply not enough. One must remember that the assigned numerical labels are not related to each other in an ordinal sense, therefore we use a technique called 'OneHotEncoding' which, what basically does is, the following :\n",
    "\n",
    "A column representing a categorical attribute is split into multiple columns such that we have new columns equal to the number of all the numerical labels used for encoding the values contained within the column under consideration. Inorder to expand upon what has just been stated, consider the following, the column of the dataframe named 'job' contains 41118 values, these 41118 values have been assigned numerical labels using integers from 0 to 12 i.e 13 integers. We will now split the 'job' column into 13 columns and each of the columns will represent an integer from 0 to 12.\n",
    "\n",
    "For a particular observation (row index) if the job is encoded with a label '3', it will reflect in the newly created columns in the following way, the column that reprsents label '3' will be assigned 1 whereas rest of the columns will be assigned '0' and so on. This holds true for all the encoded categorical columns.\n",
    "\n",
    "To sum up 'OneHotEncoding' can be described as the process of assigning a binary sequence of a particular 'length' to each value conatined within a 'LabelEncoded' attribute. The 'length'of the binary sequence is equal to the number of numerical labels used to represent the different values contained within a categorical column.\n",
    "\n",
    "**CAUTION!!! : WE MUST REFRAIN FROM 'OneHotEncoding' THE TARGET ATTRIBUTE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "hot_encoder=OneHotEncoder(categorical_features=[[1,4,5,6,7,8,12]])\n",
    "income_data=hot_encoder.fit_transform(income_data).toarray()\n",
    "income_data=pd.DataFrame(data=income_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>226802.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>89814.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>336951.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>160323.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7688.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>198693.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1    2    3    4    5    6    7    8    9  ...    79   80   81    82  \\\n",
       "0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   1.0  0.0  0.0  25.0   \n",
       "1  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0 ...   1.0  0.0  0.0  38.0   \n",
       "2  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0 ...   1.0  0.0  0.0  28.0   \n",
       "3  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0 ...   1.0  0.0  0.0  44.0   \n",
       "4  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   1.0  0.0  0.0  34.0   \n",
       "\n",
       "         83    84      85   86    87   88  \n",
       "0  226802.0   7.0     0.0  0.0  40.0  0.0  \n",
       "1   89814.0   9.0     0.0  0.0  50.0  0.0  \n",
       "2  336951.0  12.0     0.0  0.0  40.0  1.0  \n",
       "3  160323.0  10.0  7688.0  0.0  40.0  1.0  \n",
       "4  198693.0   6.0     0.0  0.0  30.0  0.0  \n",
       "\n",
       "[5 rows x 89 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "income_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    34014\n",
       "1.0    11208\n",
       "Name: 88, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "income_data[88].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7) Creating a training dataset by drawinng an equal number of instances of the either class :\n",
    "\n",
    "Since the dataset we have is infested with a high degree of class imabalnce, therefore to avoid the classifier from predicting well on only those instances that belong to the abundant class, we draw an equal number of instances of either class from the main dataset and use those instances to train the classifier. \n",
    "\n",
    "Once the instances have been drawn from the main datset, its remaining instances are used to test the perfromance of the classifier.Thus we must remove those instances from the main datset that had been drawn for making the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obtaining training set by sampling an equal numer of instances of eitehr class\n",
    "income_data_negative=income_data[income_data[88]==0].sample(n=3000,replace=False)\n",
    "income_data_positive=income_data[income_data[88]==1].sample(n=3000,replace=False)\n",
    "training_data=pd.concat([income_data_negative,income_data_positive])\n",
    "training_data=training_data.reindex(np.random.permutation(training_data.index))\n",
    "\n",
    "#dropping rows of the training data from the test data\n",
    "income_data=income_data.drop(training_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training data\n",
    "X_train=training_data.loc[:,0:88]\n",
    "Y_train=training_data.loc[:,88]\n",
    "\n",
    "#test data\n",
    "X_test=income_data.loc[:,0:88]\n",
    "Y_test=income_data.loc[:,88]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8) Standardizing the training and testing datasets :\n",
    "\n",
    "Standardization is defined as the process of transform the dataframe in such a way that, the variance \n",
    "of each column is equal to 1 and the mean is 0. A column is standardized by replace each value of the column by its Z-score. The Z-Score of a value is defined as the number of standard deviations away an observation is from the mean value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "standardizer=StandardScaler()\n",
    "X_train=standardizer.fit_transform(X_train)\n",
    "X_test=standardizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9) Reducing the dimensionality of the training dataset and test dataset using Principal Component Analysis (PCA) :\n",
    "\n",
    "Dimensionality reduction can be understood in the following way. Any dataset containing numerical columns can be thought of as a multi dimensional space having a specific number of dimensions. The dimensionality of the space is equal to the number of columns in the dataset.The rows of the datasets, which are also known as observations, can be thought of as vectors pointing in different directions within that multidimensional space. What PCA does is, it detrmines various unit vectors in that multi-dimensional space such that the 'statistical-variance' of projection of obervations is maximum along those vectors. The important thing to keep in mind is, PCA finds determines such unit vectors in a quantity that is much smaller than the original dimensionality of the dataset. That's why PCA is called a 'dimensionality-reduction' method. \n",
    "\n",
    "The unit vectors determined as a consequence of application of PCA are called 'Principal Components'. Each 'Principal Component' captures some proportion of variation of the data in the dataset. Onnce the principal components are determined, the observations are projected on to them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUMBER OF COMPONENTS : 67\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca_object=PCA(0.90)\n",
    "X_train=pca_object.fit_transform(X_train)\n",
    "X_test=pca_object.transform(X_test)\n",
    "print('NUMBER OF COMPONENTS :',pca_object.n_components_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have thus removed the dimensionality of the training and testing data from 89 to 65 while rertaining 90% of the variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10) Applying Voting Classifier in the frame work of Hard Voting Scheme :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In *Hard-Voting* class labels are designated to instaces based on, which among all the class labels has been predicted by the maximum number of classifiers or which class labels has recieved the maximum number of votes. \n",
    "We will use, LogisticRegression, RandomForestClassifier,LogisticRegression and Support Vector Classifier in the voting ensemble. We will then evaluate the performance of each of these classifiers and compare their individual performance to the performance of their collective ensemble(Voting Classifier)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on LogisticRegression : 93.36086890010708\n",
      "Accuracy on DecisionTreeClassifier : 92.09627250012747\n",
      "Accuracy on RandomForestClassifier : 96.02773953393505\n",
      "Accuracy on SVC : 96.83086023150273\n",
      "Accuracy on VotingClassifier : 97.46315843149253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\User1\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "\n",
    "voting_clf=VotingClassifier(voting='hard',estimators=[('logreg',LogisticRegression()),('tree_clf',DecisionTreeClassifier()),\n",
    "                                                     ('rfc_clf',RandomForestClassifier()),('svm_clf',SVC(probability=True))])\n",
    "\n",
    "for clf in [LogisticRegression(),DecisionTreeClassifier(),RandomForestClassifier(),SVC(),voting_clf]:\n",
    "    clf.fit(X_train,Y_train)\n",
    "    Y_pred=clf.predict(X_test)\n",
    "    print('Accuracy on',clf.__class__.__name__,':',100*accuracy_score(Y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion :\n",
    "\n",
    "From the above results, we can clearly see that the performance of the voting classifier based on an ensemble of different classifiers is better than that of any of the individual classifiers that make the ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
