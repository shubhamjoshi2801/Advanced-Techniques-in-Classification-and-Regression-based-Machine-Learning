{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Objective of the case study : To demonstrate the effect of sampling data uniformly across the classes.\n",
    "\n",
    "Classification models perform poorly on datasets with **class imbalance**. Class imbalance refers to a condition in which instances of one class have an overwhelming majority over instances of the other class/classes. As a result of class imbalance, a classification model performs extremely well on instances of the class that are present in abundance, whereas the performance of the model is extremely poor on instances that belong to the scarce class. In this case study I wish to demonstrate that the aforementioned problem, in the context of binary classification, can be addressed by training the classifier on a datset created by extracting equal number of samples of either class. It has been demonstrated in this case study that a classifier trained on such a dataset has an extremely balanced performance i.e it does equally well on classfying instances of either class correctly.\n",
    "________________________________________________________________________________________________________________________________\n",
    "\n",
    "#### Approach :\n",
    "\n",
    "We will train the classifier on a dataset obtained by sampling exactly an equal number of instances of either class. The performance of the classifier will be evaluated on the original dataset, with the sampled instances removed from it.\n",
    "\n",
    "________________________________________________________________________________________________________________________________\n",
    "\n",
    "#### Data Set Information :\n",
    "\n",
    "DATA SOURCE : https://archive.ics.uci.edu/ml/machine-learning-databases/00222/\n",
    "\n",
    "The dataset that we have has been derived from a marketing campaign run by a Portugese Banking Institution between 2008 and 2013. By training a classifier on the dataset we have, we want to evolve a model that can be used to asses the likelihood of a client subscribing to term deposit when contacted over the telephone. Clients which have a high likelihood of subscribing to the term deposit are accorded 1 and those having low likelihood are accorded 0 by the classifier.\n",
    "________________________________________________________________________________________________________________________________\n",
    "\n",
    "#### Input Features :\n",
    "\n",
    "#### Bank Client data:\n",
    "1 - age (numeric)\n",
    "\n",
    "2 - job : type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')\n",
    "\n",
    "3 - marital : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)\n",
    "\n",
    "4 - education (categorical: 'basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown')\n",
    "\n",
    "5 - default: has credit in default? (categorical: 'no','yes','unknown')\n",
    "\n",
    "6 - housing: has housing loan? (categorical: 'no','yes','unknown')\n",
    "\n",
    "7 - loan: has personal loan? (categorical: 'no','yes','unknown')\n",
    "\n",
    "#### Related with the last contact of the current campaign :\n",
    "\n",
    "8 - contact: contact communication type (categorical: 'cellular','telephone') \n",
    "\n",
    "9 - month: last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')\n",
    "\n",
    "10 - day_of_week: last contact day of the week (categorical: 'mon','tue','wed','thu','fri')\n",
    "\n",
    "11 - duration: last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.\n",
    "\n",
    "#### Other attributes/input features :\n",
    "\n",
    "12 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n",
    "\n",
    "13 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)\n",
    "\n",
    "14 - previous: number of contacts performed before this campaign and for this client (numeric)\n",
    "\n",
    "15 - poutcome: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')\n",
    "\n",
    "#### Social and Economic Context attributes/input features :\n",
    "\n",
    "16 - emp.var.rate: employment variation rate - quarterly indicator (numeric)\n",
    "\n",
    "17 - cons.price.idx: consumer price index - monthly indicator (numeric) \n",
    "\n",
    "18 - cons.conf.idx: consumer confidence index - monthly indicator (numeric) \n",
    "\n",
    "19 - euribor3m: euribor 3 month rate - daily indicator (numeric)\n",
    "\n",
    "20 - nr.employed: number of employees - quarterly indicator (numeric)\n",
    "\n",
    "#### Output Feature / Target Feature :\n",
    "\n",
    "21 - y - has the client subscribed a term deposit? (binary: 'yes','no')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Loading the dataset into the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age        job  marital    education  default housing loan    contact  \\\n",
       "0   56  housemaid  married     basic.4y       no      no   no  telephone   \n",
       "1   57   services  married  high.school  unknown      no   no  telephone   \n",
       "2   37   services  married  high.school       no     yes   no  telephone   \n",
       "3   40     admin.  married     basic.6y       no      no   no  telephone   \n",
       "4   56   services  married  high.school       no      no  yes  telephone   \n",
       "\n",
       "  month day_of_week ...  campaign  pdays  previous     poutcome emp.var.rate  \\\n",
       "0   may         mon ...         1    999         0  nonexistent          1.1   \n",
       "1   may         mon ...         1    999         0  nonexistent          1.1   \n",
       "2   may         mon ...         1    999         0  nonexistent          1.1   \n",
       "3   may         mon ...         1    999         0  nonexistent          1.1   \n",
       "4   may         mon ...         1    999         0  nonexistent          1.1   \n",
       "\n",
       "   cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
       "0          93.994          -36.4      4.857       5191.0  no  \n",
       "1          93.994          -36.4      4.857       5191.0  no  \n",
       "2          93.994          -36.4      4.857       5191.0  no  \n",
       "3          93.994          -36.4      4.857       5191.0  no  \n",
       "4          93.994          -36.4      4.857       5191.0  no  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "bank_data=pd.read_csv('bank-additional-full.csv',sep=';')\n",
    "bank_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Checking for Class Imbalance :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no     36548\n",
       "yes     4640\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank_data['y'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 36548 instances which belong to the class 'no', whereas there are just 4640 instances that belong to the class yes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  3) DEMONSTRATING THE EFFECT OF UNIFORM SAMPLING :\n",
    "\n",
    "Note: In this section we shall only focus on the effect of sampling uniformly across the class labels without delving into the specifics of the code. The codes will be discussed in the subsequent sections of the case study."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1) Creating a balanced dataframe:\n",
    "In the dataframe we have, the number of instances for which the target label is **no** outnumbers the number of instances for which the target label is **yes** by a crushing margin. A model trained on a dataset bearing such a high degree of **class imbalance** , when fed with an equal number of instances of either class, the proportion of correct predictions is quite likely\n",
    "to be much higher for instances that  belong to the abundant class. Thus the model, for a given test observation,\n",
    "will have a 'bias' towards predicting the class label that is present in abundance. This 'bias' problem can either be resolved by training the model on an equal number of samples of either class or by tweaking the prediction threshold of class label. In this case study we shall focus our attention on the former approach. The following piece of code elaborates what has just been stated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2) Coding a classification model that is trained on a dataset infested with high class-imbalance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION_MATRIX\n",
      " [[5831  396]\n",
      " [ 345  428]]\n",
      "PERCETAGE OF CORRECT PREDICTIONS ON THE ABUNDANT CLASS: 93.64059739842621\n",
      "PERCETAGE OF CORRECT PREDICTIONS ON THE SCRACE CLASS: 55.368693402328596\n"
     ]
    }
   ],
   "source": [
    "categorical_columns=bank_data.select_dtypes(include=object).columns\n",
    "categorical_indices=[]\n",
    "for column in categorical_columns:\n",
    "    categorical_indices.append(bank_data.columns.get_loc(column))\n",
    "bank_data.iloc[:,categorical_indices].head()\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder=LabelEncoder()\n",
    "for column in categorical_indices:\n",
    "    bank_data.iloc[:,column]=encoder.fit_transform(bank_data.iloc[:,column])\n",
    "\n",
    "\n",
    "X=bank_data.loc[:,'age':'nr.employed']\n",
    "Y=bank_data.loc[:,'y']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=7000,random_state=0)\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "tree_clf=DTC()\n",
    "tree_clf.fit(X_train,Y_train)\n",
    "Y_pred=tree_clf.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(Y_test,Y_pred)\n",
    "print('CONFUSION_MATRIX\\n',cm)\n",
    "\n",
    "print('PERCETAGE OF CORRECT PREDICTIONS ON THE ABUNDANT CLASS:',100*(cm[0,0]/(cm[0,0]+cm[0,1])))\n",
    "print('PERCETAGE OF CORRECT PREDICTIONS ON THE SCRACE CLASS:',100*(cm[1,1]/(cm[1,0]+cm[1,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outcome of the code in the above cell greatly exemplifies the effect of training a classifier on a \n",
    "dataset replete with high class imbalance. The classifier predicts the instances that belong to class 'no' with a staggering accuracy of 93.64% but performs poorly, with a score of just 55.36%, on instances which belong to class 'yes'. In the upcoming piece of code we will examine the effect of training a classifier on a dataset that has been obtained by sampling an equal number of instances of either class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2) Coding a classification model trained on a datset containing equal number of intsances of either class :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION_MATRIX\n",
      " [[28051  5497]\n",
      " [  284  1356]]\n",
      "PERCETAGE OF CORRECT PREDICTIONS ON THE ABUNDANT CLASS: 83.61452247525934\n",
      "PERCENTAGE OF CORRECT PREDICTIONS ON THE SCARCE CLASS: 82.68292682926828\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "bank_data=pd.read_csv('bank-additional-full.csv',sep=';')\n",
    "\n",
    "categorical_columns=bank_data.select_dtypes(include=object).columns\n",
    "categorical_indices=[]\n",
    "for column in categorical_columns:\n",
    "    categorical_indices.append(bank_data.columns.get_loc(column))\n",
    "bank_data.iloc[:,categorical_indices].head()\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder=LabelEncoder()\n",
    "for column in categorical_indices:\n",
    "    bank_data.iloc[:,column]=encoder.fit_transform(bank_data.iloc[:,column])\n",
    "    \n",
    "data_positive=bank_data[bank_data['y']==1].sample(n=3000,replace=False,random_state=0)\n",
    "data_negative=bank_data[bank_data['y']==0].sample(n=3000,replace=False,random_state=0)\n",
    "\n",
    "list1=[data_positive,data_negative]\n",
    "training_data=pd.concat(list1)\n",
    "training_data=training_data.reindex(np.random.permutation(training_data.index))\n",
    "bank_data=bank_data.drop(training_data.index)\n",
    "\n",
    "X_train=training_data.loc[:,'age':'nr.employed'].values\n",
    "X_test=bank_data.loc[:,'age':'nr.employed'].values\n",
    "Y_train=training_data.loc[:,'y'].values\n",
    "Y_test=bank_data.loc[:,'y'].values\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree_clf=DecisionTreeClassifier()\n",
    "tree_clf.fit(X_train,Y_train)\n",
    "Y_pred=tree_clf.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(Y_test,Y_pred)\n",
    "print('CONFUSION_MATRIX\\n',cm)\n",
    "\n",
    "print('PERCETAGE OF CORRECT PREDICTIONS ON THE ABUNDANT CLASS:',100*(cm[0,0]/(cm[0,0]+cm[0,1])))\n",
    "print('PERCENTAGE OF CORRECT PREDICTIONS ON THE SCARCE CLASS:',100*(cm[1,1]/(cm[1,0]+cm[1,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is pretty evident from the above piece of code that sampling instances unidormly across the class labels leads to an overall boost in accuracy of predictions.Even though the the accuracy on the instances that belong to the 'abundant' class labels has diminished from 93.54% to 83.61% but the accuracy of predictions on instances that belong to the 'scarce' class label has increased from 55.36% to 82.68%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) DELVING INTO THE CODES : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  4.1) Importing the 'Bank Marketing Dataset' :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "bank_data=pd.read_csv('bank-additional-full.csv',sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2) 'LabelEncoding' the dataset :\n",
    "\n",
    "Label Encoding is the process of assigning numerical labels to values contained within categorical input features of the\n",
    "dataframe. Label Encoding is performed inorder to facilitate the application of predictive mathematical models such\n",
    "as **Logistic Regression**, **Support Vector Machines**, **Naive-Baye's** etc, to those datasets which contain categorical/non-numerical data. Label Encoding is performed in two stages which are as follows:\n",
    "\n",
    "1) The Categorical attributes have to be fetched from the main dataframe.\n",
    "\n",
    "2) The values contained within the categorical attributes have been assigned numerical labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.1) Fetching the categorical attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         job  marital    education  default housing loan    contact month  \\\n",
       "0  housemaid  married     basic.4y       no      no   no  telephone   may   \n",
       "1   services  married  high.school  unknown      no   no  telephone   may   \n",
       "2   services  married  high.school       no     yes   no  telephone   may   \n",
       "3     admin.  married     basic.6y       no      no   no  telephone   may   \n",
       "4   services  married  high.school       no      no  yes  telephone   may   \n",
       "\n",
       "  day_of_week     poutcome   y  \n",
       "0         mon  nonexistent  no  \n",
       "1         mon  nonexistent  no  \n",
       "2         mon  nonexistent  no  \n",
       "3         mon  nonexistent  no  \n",
       "4         mon  nonexistent  no  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_columns=bank_data.select_dtypes(include=object).columns\n",
    "categorical_indices=[]\n",
    "for column in categorical_columns:\n",
    "    categorical_indices.append(bank_data.columns.get_loc(column))\n",
    "bank_data.iloc[:,categorical_indices].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.2) Assigning numerical labels / 'LabelEncoding' the categorical attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  job  marital  education  default  housing  loan  contact  month  \\\n",
       "0   56    3        1          0        0        0     0        1      6   \n",
       "1   57    7        1          3        1        0     0        1      6   \n",
       "2   37    7        1          3        0        2     0        1      6   \n",
       "3   40    0        1          1        0        0     0        1      6   \n",
       "4   56    7        1          3        0        0     2        1      6   \n",
       "\n",
       "   day_of_week ...  campaign  pdays  previous  poutcome  emp.var.rate  \\\n",
       "0            1 ...         1    999         0         1           1.1   \n",
       "1            1 ...         1    999         0         1           1.1   \n",
       "2            1 ...         1    999         0         1           1.1   \n",
       "3            1 ...         1    999         0         1           1.1   \n",
       "4            1 ...         1    999         0         1           1.1   \n",
       "\n",
       "   cons.price.idx  cons.conf.idx  euribor3m  nr.employed  y  \n",
       "0          93.994          -36.4      4.857       5191.0  0  \n",
       "1          93.994          -36.4      4.857       5191.0  0  \n",
       "2          93.994          -36.4      4.857       5191.0  0  \n",
       "3          93.994          -36.4      4.857       5191.0  0  \n",
       "4          93.994          -36.4      4.857       5191.0  0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder=LabelEncoder()\n",
    "for column in categorical_indices:\n",
    "    bank_data.iloc[:,column]=encoder.fit_transform(bank_data.iloc[:,column])\n",
    "bank_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3) OneHotEncoding the 'LabelEncoded' attributes:\n",
    "\n",
    "In order to facilitate the application of mathamatical models to datasets, merely assigning numerical labels to categorical attributes is simply not enough. One must remember that the assigned numerical labels are not related to each other in an ordinal sense, therefore we use a technique called 'OneHotEncoding' which, what basically does is, the following :\n",
    "\n",
    "A column representing a categorical attribute is split into multiple columns such that we have new columns equal to the number of all the numerical labels used for encoding the values contained within the column under consideration. Inorder to expand upon what has just been stated, consider the following, the column of the dataframe named 'job' contains 41118 values, these 41118 values have been assigned numerical labels using integers from 0 to 12 i.e 13 integers. We will now split the 'job' column into 13 columns and each of the columns will represent an integer from 0 to 12.\n",
    "\n",
    "For a particular observation (row index) if the job is encoded with a label '3', it will reflect in the newly created columns in the following way, the column that reprsents label '3' will be assigned 1 whereas rest of the columns will be assigned '0' and so on. This holds true for all the encoded categorical columns.\n",
    "\n",
    "To sum up 'OneHotEncoding' can be described as the process of assigning a binary sequence of a particular 'length' to each value conatined within a 'LabelEncoded' attribute. The 'length'of the binary sequence is equal to the number of numerical labels used to represent the different values contained within a categorical column.\n",
    "\n",
    "**CAUTION!!! : WE MUST REFRAIN FROM 'OneHotEncoding' THE TARGET ATTRIBUTE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.1) 'OneHotEncoding' the 'LabelEncoded' features :\n",
    "\n",
    "**Sequence of steps:**\n",
    "\n",
    "1) Import **OneHotEncoder** class from preprocessing module.\n",
    "\n",
    "2) Instantiate an object of the **OneHotEncoder** class and feed it the categorical input indices that are to be hot encoded.\n",
    "\n",
    "3) Apply **OneHotEncoding** to the input features.\n",
    "\n",
    "4) Create a table containing the splits rendered to each input categorical feature.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Categorical_index</th>\n",
       "      <th>Number_of_splits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Categorical_index  Number_of_splits\n",
       "0                  1                12\n",
       "1                  2                 4\n",
       "2                  3                 8\n",
       "3                  4                 3\n",
       "4                  5                 3\n",
       "5                  6                 3\n",
       "6                  7                 2\n",
       "7                  8                10\n",
       "8                  9                 5\n",
       "9                 14                 3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "X=bank_data.loc[:,'age':'nr.employed']\n",
    "hot_encoder=OneHotEncoder(categorical_features=[1,2,3,4,5,6,7,8,9,14])\n",
    "X=hot_encoder.fit_transform(X).toarray()\n",
    "Y=bank_data.loc[:,'y'].values\n",
    "categorical_column_splitting=pd.DataFrame(data={'Categorical_index':[1,2,3,4,5,6,7,8,9,14],\n",
    "                                               'Number_of_splits':hot_encoder.n_values_})\n",
    "categorical_column_splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.2) Creating a Dataframe of Hot Encoded features :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>261.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>149.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>226.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>151.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>307.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1    2    3    4    5    6    7    8    9  ...     54   55     56  \\\n",
       "0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0 ...  261.0  1.0  999.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...  149.0  1.0  999.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...  226.0  1.0  999.0   \n",
       "3  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...  151.0  1.0  999.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...  307.0  1.0  999.0   \n",
       "\n",
       "    57   58      59    60     61      62  63  \n",
       "0  0.0  1.1  93.994 -36.4  4.857  5191.0   0  \n",
       "1  0.0  1.1  93.994 -36.4  4.857  5191.0   0  \n",
       "2  0.0  1.1  93.994 -36.4  4.857  5191.0   0  \n",
       "3  0.0  1.1  93.994 -36.4  4.857  5191.0   0  \n",
       "4  0.0  1.1  93.994 -36.4  4.857  5191.0   0  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe=pd.DataFrame(data=X)\n",
    "dataframe[63]=Y\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4) Extracting the training data and testing data from the 'OneHotEncoded' Dataframe:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4.1) Sampling the training data :\n",
    "\n",
    "Training data refers to the data that is fed to a predictive model inorder to enable it to make predictions on observations it has never seen before. Since the dataset we're dealing with has high 'class-imbalance' thus we have to sample an equal number of instances of either class. The following is the sequence of steps that has been followed in the code:\n",
    "\n",
    "1) Choose 3000 samples of class '0' and save those in a dataframe named 'dataframe_negative'.\n",
    "\n",
    "2) Choose 3000 samples of class '1' and save those in a dataframe names 'dataframe_positive'.\n",
    "\n",
    "3) Concatenate the dataframes thus created to for a new dataframe and name it 'training data'.\n",
    "\n",
    "4) Sample the training data along all the rows of all the training features of 'training_data'.\n",
    "\n",
    "5) Sample the testing_data along all the rows of all the target features of 'training_data'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_negative=dataframe[dataframe[63]==0].sample(n=3000,replace=False,random_state=0)\n",
    "dataframe_positive=dataframe[dataframe[63]==1].sample(n=3000,replace=False,random_state=0)\n",
    "\n",
    "list1=[dataframe_negative,dataframe_positive]\n",
    "training_data=pd.concat(list1)\n",
    "\n",
    "training_data=training_data.reindex(np.random.permutation(training_data.index))\n",
    "\n",
    "X_train=training_data.iloc[:,0:63].values\n",
    "Y_train=training_data.iloc[:,63].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4.2) Sampling the testing data :\n",
    "\n",
    "Testing data refers to the data that is used to evaluate the performance of a predictive model once it has been trained on some data. Following are the steps involved in sampling the testing data.\n",
    "\n",
    "1) From the main dataframe we remove all those observations that are in the training set.\n",
    "\n",
    "2) The datarame is sampled along all the rows of all the training features of the source dataframe.\n",
    "\n",
    "3) The dataframe is sampled along all the rows of the target feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe=dataframe.drop(training_data.index)\n",
    "X_test=dataframe.iloc[:,0:63].values\n",
    "Y_test=dataframe.iloc[:,63].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  4.5) Standardizing the Data :\n",
    "\n",
    "Standardization is defined as the process of transform the dataframe in such a way that, the variance \n",
    "of each column is equal to 1 and the mean is 0. A column is standardized by replace each value of the column by its Z-score. The Z-Score of a value is defined as the number of standard deviations away an observation is from the mean value.\n",
    "\n",
    "Sequence of steps:\n",
    "\n",
    "1) Import the 'StandardScaler' class from sklearn's 'preprocessing' module.\n",
    "\n",
    "2) Instantiate an object of the 'StandardScaler' class.\n",
    "\n",
    "3) Standardize the training set using the '.fit_transform()' method.\n",
    "\n",
    "4) Standardize the testing set using the '.transform()' method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "standardizer=StandardScaler()\n",
    "X_train=standardizer.fit_transform(X_train)\n",
    "X_test=standardizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.6) Dimensionality Reduction using Principal Component Analysis (PCA) :\n",
    "\n",
    "Dimensionality reduction can be understood in the following way. Any dataset containing numerical columns can be thought of as a multi dimensional space having a specific number of dimensions. The dimensionality of the space is equal to the number of columns in the dataset.The rows of the datasets, which are also known as observations, can be thought of as vectors pointing in different directions within that multidimensional space. What PCA does is, it detrmines various unit vectors in that multi-dimensional space such that the 'statistical-variance' of projection of obervations is maximum along those vectors. The important thing to keep in mind is, PCA finds determines such unit vectors in a quantity that is much smaller than the original dimensionality of the dataset. That's why PCA is called a 'dimensionality-reduction' method. \n",
    "\n",
    "The unit vectors determined as a consequence of application of PCA are called 'Principal Components'. Each 'Principal Component' captures some proportion of variation of the data in the dataset. Onnce the principal components are determined, the observations are projected on to them.\n",
    "\n",
    "Sequence of Steps:\n",
    "\n",
    "1) From the decomposition module of sklearn, import PCA.\n",
    "\n",
    "2) Instantiate an object of PCA class and pass the proportion of total variance to be preserved.\n",
    "\n",
    "3) Fit the object on the training data.\n",
    "\n",
    "4) Apply the object to the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUMBER OF PRINCIPAL COMPONENTS: 41\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca_object=PCA(0.95)\n",
    "X_train=pca_object.fit_transform(X_train)\n",
    "X_test=pca_object.transform(X_test)\n",
    "print('NUMBER OF PRINCIPAL COMPONENTS:',pca_object.n_components_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.7) Fitting Models and making Predictions:\n",
    "\n",
    "Now we are going to fit various models on our training data and observe the performace of each model on the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERFORMANCE ON LogisticRegression CLASSIFIER\n",
      "ACCURACY_SCORE:  85.95543935432534\n",
      "CONFUSION_MATRIX : \n",
      " [[28819  4729]\n",
      " [  213  1427]]\n",
      "PERCETAGE OF CORRECT PREDICTIONS OF THE ABUNDANT CLASS : 85.90377965899606\n",
      "PERCETAGE OF CORRECT PREDICTIONS OF THE SCARCE CLASS: 87.01219512195122\n",
      "____________________________________________________\n",
      "PERFORMANCE ON DecisionTreeClassifier CLASSIFIER\n",
      "ACCURACY_SCORE:  76.4521996135046\n",
      "CONFUSION_MATRIX : \n",
      " [[25666  7882]\n",
      " [  404  1236]]\n",
      "PERCETAGE OF CORRECT PREDICTIONS OF THE ABUNDANT CLASS : 76.50530583045189\n",
      "PERCETAGE OF CORRECT PREDICTIONS OF THE SCARCE CLASS: 75.36585365853658\n",
      "____________________________________________________\n",
      "PERFORMANCE ON SVC CLASSIFIER\n",
      "ACCURACY_SCORE:  83.61089007616232\n",
      "CONFUSION_MATRIX : \n",
      " [[27938  5610]\n",
      " [  157  1483]]\n",
      "PERCETAGE OF CORRECT PREDICTIONS OF THE ABUNDANT CLASS : 83.27769166567307\n",
      "PERCETAGE OF CORRECT PREDICTIONS OF THE SCARCE CLASS: 90.42682926829269\n",
      "____________________________________________________\n",
      "PERFORMANCE ON KNeighborsClassifier CLASSIFIER\n",
      "ACCURACY_SCORE:  79.98465385927021\n",
      "CONFUSION_MATRIX : \n",
      " [[26994  6554]\n",
      " [  489  1151]]\n",
      "PERCETAGE OF CORRECT PREDICTIONS OF THE ABUNDANT CLASS : 80.46381304399665\n",
      "PERCETAGE OF CORRECT PREDICTIONS OF THE SCARCE CLASS: 70.18292682926828\n",
      "____________________________________________________\n",
      "PERFORMANCE ON VotingClassifier CLASSIFIER\n",
      "ACCURACY_SCORE:  86.71422075707628\n",
      "CONFUSION_MATRIX : \n",
      " [[29191  4357]\n",
      " [  318  1322]]\n",
      "PERCETAGE OF CORRECT PREDICTIONS OF THE ABUNDANT CLASS : 87.01263860736854\n",
      "PERCETAGE OF CORRECT PREDICTIONS OF THE SCARCE CLASS: 80.60975609756098\n",
      "____________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\User1\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "voting_clf=VotingClassifier(voting='hard',estimators=[('clf1',LogisticRegression()),('clf2',SVC()),('clf3',DTC()),('clf4',KNC())])\n",
    "\n",
    "for clf in [LogisticRegression(),DTC(),SVC(),KNC(),voting_clf]:\n",
    "    clf.fit(X_train,Y_train)\n",
    "    Y_pred=clf.predict(X_test)\n",
    "    cm=confusion_matrix(Y_test,Y_pred)\n",
    "    print('PERFORMANCE ON',clf.__class__.__name__,'CLASSIFIER')\n",
    "    print('ACCURACY_SCORE: ',100*accuracy_score(Y_test,Y_pred))\n",
    "    print('CONFUSION_MATRIX : \\n',confusion_matrix(Y_test,Y_pred))\n",
    "    print('PERCETAGE OF CORRECT PREDICTIONS OF THE ABUNDANT CLASS :',100*(cm[0,0]/(cm[0,0]+cm[0,1])))\n",
    "    print('PERCETAGE OF CORRECT PREDICTIONS OF THE SCARCE CLASS:',100*(cm[1,1]/(cm[1,0]+cm[1,1])))\n",
    "    print('____________________________________________________')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.8) Outcome :\n",
    "\n",
    "From the results it is evident that training a classifier on a dataset created by sampling instances unoformly across all the classes performs equally well on instances of either class as opposed to a classifier trained on a dataset bearing high class imbalance, which does extremely one well on instances of the abundant class, but performs poorly on instances that belong to the minority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
