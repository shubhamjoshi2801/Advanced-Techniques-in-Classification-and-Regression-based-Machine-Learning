{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective :\n",
    "\n",
    "The objective of this case study is to demonstrate an **ensembling** technique popular by the name of **Bagging or Bootstrap Aggregation**. Ensembling basically involves stacking together multiple ***weak classifier*** inorder to obtain a ***meta-classifer*** substantially powerful than the original classifier.\n",
    "\n",
    "Bagging involves the following steps :\n",
    "\n",
    "1) We choose the type and number of classifiers to build the ensemble.\n",
    "\n",
    "2) For each classifier in the ensemble, we draw a specific number of instances from the training data with replacement. The   dataset thus obtained is known as a bootstrapped dataset.\n",
    "\n",
    "3) Each classifier is trained on the corresponding bootstrapped dataset.\n",
    "\n",
    "4) Instances from the test set are fed to the ensemble, instances are designated that class label which has been predicted by the maximum number of classifiers contained within the ensemble. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data :\n",
    "\n",
    "**Data Source ** : https://archive.ics.uci.edu/ml/machine-learning-databases/abalone/abalone.data\n",
    "\n",
    "**About the Data** : The dataset that we have is popular in the machine learning community by the name of 'Abalone Dataset'. Abalone refers to the small to very large snails that dwell at ocean surface. In the context of classification based machine learning, thise dataset is used for predicting the gender (male,female or infant) of an abalone based on attributes such as Length, diameter, weight etc.\n",
    "\n",
    "**Input Attributes**:\n",
    "\n",
    "1) Length : continuous \n",
    "\n",
    "2) Diameter: continuous\n",
    "\n",
    "3) Height : continuous\n",
    "\n",
    "4) Whole Weight : continuous\n",
    "\n",
    "5) Shucked weight : continuous : weight of the meat\n",
    "\n",
    "6) Viscera weight : continuous : weight after bleeding\n",
    "\n",
    "7) Shell weight : continuous : weight after being dried\n",
    "\n",
    "8) Rings : integer : No of rings\n",
    "\n",
    "\n",
    "** Target Attribute**:\n",
    "\n",
    "9) Sex : categorical: (male,female,infant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Importing the relevant libraries :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Loading the dataset :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['sex','length','diameter','height','whole_weight','shuckled_weight','viscerea_weight','shell_weight','rings']\n",
    "abalone_data=pd.read_table('https://archive.ics.uci.edu/ml/machine-learning-databases/abalone/abalone.data',sep=',',header=None,\n",
    "                           names=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>length</th>\n",
       "      <th>diameter</th>\n",
       "      <th>height</th>\n",
       "      <th>whole_weight</th>\n",
       "      <th>shuckled_weight</th>\n",
       "      <th>viscerea_weight</th>\n",
       "      <th>shell_weight</th>\n",
       "      <th>rings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.150</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.070</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.210</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.155</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.055</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sex  length  diameter  height  whole_weight  shuckled_weight  \\\n",
       "0   M   0.455     0.365   0.095        0.5140           0.2245   \n",
       "1   M   0.350     0.265   0.090        0.2255           0.0995   \n",
       "2   F   0.530     0.420   0.135        0.6770           0.2565   \n",
       "3   M   0.440     0.365   0.125        0.5160           0.2155   \n",
       "4   I   0.330     0.255   0.080        0.2050           0.0895   \n",
       "\n",
       "   viscerea_weight  shell_weight  rings  \n",
       "0           0.1010         0.150     15  \n",
       "1           0.0485         0.070      7  \n",
       "2           0.1415         0.210      9  \n",
       "3           0.1140         0.155     10  \n",
       "4           0.0395         0.055      7  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abalone_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Label encoding the categorical attributes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder \n",
    "encoder=LabelEncoder()\n",
    "abalone_data['sex']=encoder.fit_transform(abalone_data['sex'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) Segregating the input features and target feature :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=abalone_data.loc[:,'length':'rings'].values\n",
    "Y=abalone_data.loc[:,'sex'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5) Splitting the dataframe into training set and testing set :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=300,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6) Standardizing the training data and testing data :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "standardizer=StandardScaler()\n",
    "X_train=standardizer.fit_transform(X_train)\n",
    "X_test=standardizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7) Reducing the dimensionality of the data using Principal Component Analysis (PCA) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of components : 3\n",
      "explained variance ratio : [0.83756569 0.08773401 0.03301425]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca_object=PCA(0.95)\n",
    "X_train=pca_object.fit_transform(X_train)\n",
    "X_test=pca_object.transform(X_test)\n",
    "print('number of components :',pca_object.n_components_)\n",
    "print('explained variance ratio :',pca_object.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8) Fitting the training data on the Decision Tree Classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using DecisionTreeClassifier: 44.0\n",
      "Confusion Matrix:\n",
      " [[33 11 40]\n",
      " [23 52 19]\n",
      " [58 17 47]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "tree_clf=DecisionTreeClassifier()\n",
    "tree_clf.fit(X_train,Y_train)\n",
    "Y_pred=tree_clf.predict(X_test)\n",
    "print('Accuracy using DecisionTreeClassifier:',100* accuracy_score(Y_test,Y_pred))\n",
    "print('Confusion Matrix:\\n',confusion_matrix(Y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9) Tuning the hyperparameters of Bagging Classifier:\n",
    "\n",
    "n_estimators : The number of estimators in the ensemble.\n",
    "\n",
    "max_samples : The maximum number of samples to be bootstrapped.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 49 candidates, totalling 245 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done  22 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=5)]: Done 118 tasks      | elapsed:   40.4s\n",
      "[Parallel(n_jobs=5)]: Done 245 out of 245 | elapsed:  2.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            ...n_estimators=10, n_jobs=1, oob_score=False,\n",
       "         random_state=None, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=5,\n",
       "       param_grid={'n_estimators': [150, 300, 450, 600, 750, 900, 1050], 'max_samples': [150, 300, 450, 600, 750, 900, 1050]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "hyperparams={'n_estimators':[150,300,450,600,750,900,1050],'max_samples':[150,300,450,600,750,900,1050]}\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_object=GridSearchCV(estimator=BaggingClassifier(base_estimator=DecisionTreeClassifier(),bootstrap=True),cv=5,param_grid=hyperparams,scoring='accuracy',verbose=3,n_jobs=5)\n",
    "grid_object.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10) Determining the best parameters :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_samples': 450, 'n_estimators': 750}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_object.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11) Making predictions with the ensemble with its hyperparameters tuned :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Using Bagging Classifier : 54.333333333333336\n"
     ]
    }
   ],
   "source": [
    "bagging_clf=BaggingClassifier(base_estimator=DecisionTreeClassifier(),max_samples=450,n_estimators=750,max_features=3)\n",
    "bagging_clf.fit(X_train,Y_train)\n",
    "Y_pred=bagging_clf.predict(X_test)\n",
    "print('Accuracy Using Bagging Classifier :',100*accuracy_score(Y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11) Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy using DecisionTreeClassifier : 44%\n",
    "\n",
    "Accuracy using Bagging Classifier : 54.33 %\n",
    "\n",
    "We thus observe that when we use an ensemble of DecisionTreeClassifiers trained on bootstrapped samples of the original dataset instead of a single DecisionTreeClassifier trained on the original dataset, the performance of the former exceeds the latter by a significant margin, when assesed on the basis of accuracy i.e the proportion of the correctly predicted instances to the total no of instances in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
